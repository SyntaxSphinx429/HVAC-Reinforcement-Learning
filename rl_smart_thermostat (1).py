# -*- coding: utf-8 -*-
"""RL smart thermostat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P9RjcYleKcrNDA2LDMGC2KOpls40k7gj
"""

import streamlit as st
import numpy as np
import pandas as pd
import random
import time

# ==========================================
# 1. PAGE CONFIGURATION
# ==========================================
st.set_page_config(page_title="Highland HVAC Agent (Cameron/Genting)", layout="wide")

st.title("üçì Cameron & Genting Highlands HVAC Controller")
st.markdown("""
This AI Agent is optimized for **Malaysian Highlands**.
It handles the unique **"Cool Night / Mild Day"** climate where you might need **Heating** at night but **No Cooling** during the day.
""")

# ==========================================
# 2. CONFIGURATION & HYPERPARAMETERS
# ==========================================
ALPHA = 0.1     # Learning Rate
GAMMA = 0.9     # Discount Factor
EPSILON = 0.1   # Exploration Rate

# --- HIGHLAND CLIMATE SETTINGS ---
# Indoor: 12¬∞C (Cold room) to 30¬∞C
T_IN_RANGE = np.arange(12, 31, 1)
# Outdoor: 13¬∞C (Night) to 26¬∞C (Afternoon)
T_OUT_RANGE = np.arange(13, 27, 1)
OCCUPANCY_STATES = [0, 1]

# Actions: [Off, Low Heat, High Heat, Low Cool, High Cool]
ACTIONS = [0, 1, 2, 3, 4]
ACTION_NAMES = ["OFF", "Low Heat (Heater)", "High Heat", "Fan / Low Cool", "High Cool"]

# --- MALAYSIAN COST MODEL (TNB) ---
# Power Rating (kW)
ACTION_POWER_KW = {
    0: 0.0,   # Off
    1: 1.5,   # Low Heat (Portable Electric Heater)
    2: 2.5,   # High Heat (Wall Heater)
    3: 0.8,   # Fan / Low AC
    4: 1.5    # High AC
}

# Average TNB Tariff (Residential Tier 2/3 Mix)
MYR_PER_KWH = 0.40

# Reward Costs (Normalized)
ACTION_REWARD_COSTS = {0: 0.0, 1: 0.6, 2: 1.2, 3: 0.4, 4: 0.9}

# Initialize Q-Table
if 'q_table' not in st.session_state:
    num_states = len(T_IN_RANGE) * len(T_OUT_RANGE) * len(OCCUPANCY_STATES)
    num_actions = len(ACTIONS)
    st.session_state.q_table = np.zeros((num_states, num_actions))
    st.session_state.is_trained = False

# ==========================================
# 3. HELPER FUNCTIONS
# ==========================================
def get_state_index(t_in, t_out, occ):
    idx_in = (np.abs(T_IN_RANGE - t_in)).argmin()
    idx_out = (np.abs(T_OUT_RANGE - t_out)).argmin()
    return (idx_in * len(T_OUT_RANGE) * len(OCCUPANCY_STATES)) + \
           (idx_out * len(OCCUPANCY_STATES)) + occ

def calculate_reward(t_in, action, occupancy, setpoint):
    w1 = 1.0 # Cost Weight
    w2 = 3.0 # Comfort Weight

    energy_cost = ACTION_REWARD_COSTS[action]

    if occupancy == 1:
        dist = abs(t_in - setpoint)
        comfort_penalty = 0 if dist <= 0.5 else dist
    else:
        comfort_penalty = 0

    return -(w1 * energy_cost) - (w2 * comfort_penalty)

def step_environment(t_in, t_out, action):
    # Highland Physics:
    # Buildings in Cameron often lack insulation (Single brick), so leakage is high!
    k = 0.20
    leakage = k * (t_out - t_in)

    hvac_impact = 0
    if action == 1: hvac_impact = 0.7   # Low Heat
    if action == 2: hvac_impact = 1.8   # High Heat
    if action == 3: hvac_impact = -0.5  # Fan/Ventilation
    if action == 4: hvac_impact = -1.5  # AC

    new_t_in = t_in + leakage + hvac_impact
    return np.clip(new_t_in, 12, 30)

# ==========================================
# 4. TRAINING SECTION
# ==========================================
with st.sidebar:
    st.header("‚öôÔ∏è Highland Settings")
    st.write("Train agent for misty mornings & cool nights:")
    train_btn = st.button("üöÄ Train Agent (Highland Mode)")

    if train_btn:
        progress_bar = st.progress(0)
        q_table = st.session_state.q_table
        target_setpoint = 22.0 # Typical comfort in highlands (warmer than outside!)

        for episode in range(10000):
            current_t_in = random.choice(T_IN_RANGE)
            current_t_out = random.choice(T_OUT_RANGE)
            current_occ = random.choice([0, 1])

            for _ in range(10):
                s_idx = get_state_index(current_t_in, current_t_out, current_occ)

                if random.uniform(0, 1) < EPSILON:
                    action = random.choice(ACTIONS)
                else:
                    action = np.argmax(q_table[s_idx])

                next_t_in = step_environment(current_t_in, current_t_out, action)
                reward = calculate_reward(next_t_in, action, current_occ, target_setpoint)
                next_s_idx = get_state_index(next_t_in, current_t_out, current_occ)

                old_val = q_table[s_idx, action]
                next_max = np.max(q_table[next_s_idx])
                new_val = old_val + ALPHA * (reward + (GAMMA * next_max) - old_val)
                q_table[s_idx, action] = new_val

                current_t_in = next_t_in

            if episode % 1000 == 0:
                progress_bar.progress(episode / 10000)

        st.session_state.is_trained = True
        progress_bar.progress(100)
        st.success("Trained! Agent understands Cameron climate.")

# ==========================================
# 5. DASHBOARD
# ==========================================
st.divider()

col_input, col_hvac, col_cost = st.columns([1, 1.5, 1])

with col_input:
    st.subheader("üå´Ô∏è Weather & Room")
    # Cameron Logic: Outside is usually COLDER than you want
    user_setpoint = st.slider("Target Temp (¬∞C)", 18, 25, 22)
    user_outdoor = st.slider("Outdoor Temp (¬∞C)", 13, 27, 16) # Default 16¬∞C (Night)
    user_indoor = st.number_input("Indoor Temp (¬∞C)", 12.0, 30.0, 18.0, step=0.5)
    user_occupancy = st.radio("Occupancy", ["Empty (0)", "Occupied (1)"], index=1)
    occ_val = 1 if "Occupied" in user_occupancy else 0

    if user_outdoor < 18:
        st.info("Currently: **Misty / Night** üåô")
    else:
        st.warning("Currently: **Sunny Afternoon** ‚òÄÔ∏è")

with col_hvac:
    st.subheader("üß† Agent Status")

    if st.session_state.is_trained:
        state_idx = get_state_index(user_indoor, user_outdoor, occ_val)
        best_action_idx = np.argmax(st.session_state.q_table[state_idx])
        predicted_action = ACTION_NAMES[best_action_idx]

        st.metric(label="Action", value=predicted_action)

        # Highland Specific Logic Display
        if occ_val == 0:
            st.info("Room Empty -> **OFF** (Saving MYR)")
        elif best_action_idx == 1 or best_action_idx == 2:
            st.warning(f"Outdoor is {user_outdoor}¬∞C (Cold). Heating to maintain {user_setpoint}¬∞C.")
        elif best_action_idx == 0 and user_indoor >= user_setpoint:
             st.success("Target met. **OFF**. Letting natural cool air handle it.")
        elif best_action_idx == 4:
             st.error("Unusual Heat! Using AC.")

    else:
        st.error("‚ö†Ô∏è Train the agent first!")

with col_cost:
    st.subheader("üí∞ TNB Bill Est.")

    if st.session_state.is_trained:
        power_kw = ACTION_POWER_KW[best_action_idx]
        hourly_cost = power_kw * MYR_PER_KWH

        st.metric(label="Power (kW)", value=f"{power_kw} kW")
        st.metric(label="Cost (MYR/Hour)", value=f"RM {hourly_cost:.3f}")

        st.caption(f"Tariff: RM {MYR_PER_KWH:.2f}/kWh")

# ==========================================
# 6. Q-TABLE VISUALIZATION
# ==========================================
st.divider()
with st.expander("üìä View Q-Table"):
    if st.session_state.is_trained:
        df = pd.DataFrame(st.session_state.q_table, columns=ACTION_NAMES)
        st.dataframe(df.head(50))